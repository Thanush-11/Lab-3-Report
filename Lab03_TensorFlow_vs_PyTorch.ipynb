{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5c1e84a1",
      "metadata": {
        "id": "5c1e84a1"
      },
      "source": [
        "# Lab 03: TensorFlow vs. PyTorch\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1c58bba",
      "metadata": {
        "id": "a1c58bba"
      },
      "source": [
        "## TensorFlow Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1dcc9d4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (2.11.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.1)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow-intel==2.11.0->tensorflow)\n",
            "  Using cached protobuf-3.19.6-cp37-cp37m-win_amd64.whl.metadata (807 bytes)\n",
            "Requirement already satisfied: setuptools in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (68.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.62.3)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.40.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (6.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
            "Using cached protobuf-3.19.6-cp37-cp37m-win_amd64.whl (896 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.24.4\n",
            "    Uninstalling protobuf-4.24.4:\n",
            "      Successfully uninstalled protobuf-4.24.4\n",
            "Successfully installed protobuf-3.19.6\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: Failed to remove contents in a temporary directory 'c:\\users\\thanush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\google\\~upb'.\n",
            "  You can safely remove it manually.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "onnx 1.14.1 requires protobuf>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "# Installing tensorflow\n",
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23ebc05e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23ebc05e",
        "outputId": "24c0a299-6c6e-44b4-bddc-08794750b2a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.4910\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9557 - loss: 0.1518\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.1046\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.0808\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9811 - loss: 0.0653\n",
            "TF Training time: 22.83 seconds\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9661 - loss: 0.1037\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.09069951623678207, 0.9714000225067139]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255   # Normalization factor\n",
        "x_test = x_test / 255     # Normalization factor\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(28, 28)),        \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),  \n",
        "    tf.keras.layers.Dense(10, activation='softmax')  \n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',       # Using categorical_crossentropy loss function\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "start = time.time()\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "end = time.time()\n",
        "print(f\"TF Training time: {end-start:.2f} seconds\")       # Outputs the training time\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72743ab8",
      "metadata": {
        "id": "72743ab8"
      },
      "source": [
        "## Convert TensorFlow model to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "be6ab50a",
      "metadata": {
        "id": "be6ab50a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\Thanush\\AppData\\Local\\Temp\\tmpzcz53sjg\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\Thanush\\AppData\\Local\\Temp\\tmpzcz53sjg\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at 'C:\\Users\\Thanush\\AppData\\Local\\Temp\\tmpzcz53sjg'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  1903041505104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  1903041506064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  1903041505488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  1903041505872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57c00c95",
      "metadata": {
        "id": "57c00c95"
      },
      "source": [
        "## PyTorch Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c2db9a0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.7.1-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
            "Collecting filelock (from torch)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\thanush\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.14.0)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch)\n",
            "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\thanush\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torch-2.7.1-cp311-cp311-win_amd64.whl (216.1 MB)\n",
            "   ---------------------------------------- 0.0/216.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/216.1 MB 2.0 MB/s eta 0:01:46\n",
            "   ---------------------------------------- 0.1/216.1 MB 2.1 MB/s eta 0:01:41\n",
            "   ---------------------------------------- 0.3/216.1 MB 2.6 MB/s eta 0:01:23\n",
            "   ---------------------------------------- 0.5/216.1 MB 3.1 MB/s eta 0:01:10\n",
            "   ---------------------------------------- 1.0/216.1 MB 4.7 MB/s eta 0:00:46\n",
            "   ---------------------------------------- 1.4/216.1 MB 5.4 MB/s eta 0:00:41\n",
            "   ---------------------------------------- 2.1/216.1 MB 7.2 MB/s eta 0:00:30\n",
            "   ---------------------------------------- 2.6/216.1 MB 7.6 MB/s eta 0:00:29\n",
            "    --------------------------------------- 3.5/216.1 MB 9.1 MB/s eta 0:00:24\n",
            "    --------------------------------------- 4.0/216.1 MB 9.6 MB/s eta 0:00:23\n",
            "    --------------------------------------- 4.8/216.1 MB 10.2 MB/s eta 0:00:21\n",
            "   - -------------------------------------- 5.5/216.1 MB 11.1 MB/s eta 0:00:20\n",
            "   - -------------------------------------- 6.2/216.1 MB 11.4 MB/s eta 0:00:19\n",
            "   - -------------------------------------- 7.1/216.1 MB 12.2 MB/s eta 0:00:18\n",
            "   - -------------------------------------- 7.8/216.1 MB 12.5 MB/s eta 0:00:17\n",
            "   - -------------------------------------- 8.5/216.1 MB 12.9 MB/s eta 0:00:17\n",
            "   - -------------------------------------- 9.3/216.1 MB 13.2 MB/s eta 0:00:16\n",
            "   - -------------------------------------- 9.8/216.1 MB 13.4 MB/s eta 0:00:16\n",
            "   - -------------------------------------- 10.5/216.1 MB 16.0 MB/s eta 0:00:13\n",
            "   -- ------------------------------------- 11.2/216.1 MB 17.7 MB/s eta 0:00:12\n",
            "   -- ------------------------------------- 12.1/216.1 MB 18.2 MB/s eta 0:00:12\n",
            "   -- ------------------------------------- 12.9/216.1 MB 18.7 MB/s eta 0:00:11\n",
            "   -- ------------------------------------- 13.7/216.1 MB 18.7 MB/s eta 0:00:11\n",
            "   -- ------------------------------------- 14.6/216.1 MB 18.7 MB/s eta 0:00:11\n",
            "   -- ------------------------------------- 15.5/216.1 MB 18.7 MB/s eta 0:00:11\n",
            "   --- ------------------------------------ 16.5/216.1 MB 19.8 MB/s eta 0:00:11\n",
            "   --- ------------------------------------ 17.4/216.1 MB 19.2 MB/s eta 0:00:11\n",
            "   --- ------------------------------------ 18.2/216.1 MB 18.7 MB/s eta 0:00:11\n",
            "   --- ------------------------------------ 19.0/216.1 MB 19.2 MB/s eta 0:00:11\n",
            "   --- ------------------------------------ 19.8/216.1 MB 18.7 MB/s eta 0:00:11\n",
            "   --- ------------------------------------ 20.7/216.1 MB 19.3 MB/s eta 0:00:11\n",
            "   ---- ----------------------------------- 21.7/216.1 MB 19.3 MB/s eta 0:00:11\n",
            "   ---- ----------------------------------- 22.6/216.1 MB 19.9 MB/s eta 0:00:10\n",
            "   ---- ----------------------------------- 23.3/216.1 MB 19.9 MB/s eta 0:00:10\n",
            "   ---- ----------------------------------- 24.3/216.1 MB 19.3 MB/s eta 0:00:10\n",
            "   ---- ----------------------------------- 24.8/216.1 MB 19.3 MB/s eta 0:00:10\n",
            "   ---- ----------------------------------- 25.5/216.1 MB 18.7 MB/s eta 0:00:11\n",
            "   ---- ----------------------------------- 26.0/216.1 MB 17.7 MB/s eta 0:00:11\n",
            "   ---- ----------------------------------- 27.0/216.1 MB 18.2 MB/s eta 0:00:11\n",
            "   ----- ---------------------------------- 28.0/216.1 MB 17.7 MB/s eta 0:00:11\n",
            "   ----- ---------------------------------- 28.8/216.1 MB 18.2 MB/s eta 0:00:11\n",
            "   ----- ---------------------------------- 29.5/216.1 MB 17.7 MB/s eta 0:00:11\n",
            "   ----- ---------------------------------- 30.2/216.1 MB 17.7 MB/s eta 0:00:11\n",
            "   ----- ---------------------------------- 31.1/216.1 MB 18.2 MB/s eta 0:00:11\n",
            "   ----- ---------------------------------- 32.1/216.1 MB 18.2 MB/s eta 0:00:11\n",
            "   ------ --------------------------------- 33.0/216.1 MB 18.2 MB/s eta 0:00:11\n",
            "   ------ --------------------------------- 34.0/216.1 MB 18.2 MB/s eta 0:00:11\n",
            "   ------ --------------------------------- 34.9/216.1 MB 18.2 MB/s eta 0:00:10\n",
            "   ------ --------------------------------- 35.9/216.1 MB 18.7 MB/s eta 0:00:10\n",
            "   ------ --------------------------------- 36.8/216.1 MB 19.3 MB/s eta 0:00:10\n",
            "   ------ --------------------------------- 37.6/216.1 MB 19.3 MB/s eta 0:00:10\n",
            "   ------- -------------------------------- 38.3/216.1 MB 19.2 MB/s eta 0:00:10\n",
            "   ------- -------------------------------- 39.3/216.1 MB 18.7 MB/s eta 0:00:10\n",
            "   ------- -------------------------------- 40.2/216.1 MB 18.7 MB/s eta 0:00:10\n",
            "   ------- -------------------------------- 41.0/216.1 MB 18.7 MB/s eta 0:00:10\n",
            "   ------- -------------------------------- 41.9/216.1 MB 18.7 MB/s eta 0:00:10\n",
            "   ------- -------------------------------- 42.9/216.1 MB 18.2 MB/s eta 0:00:10\n",
            "   -------- ------------------------------- 43.9/216.1 MB 18.2 MB/s eta 0:00:10\n",
            "   -------- ------------------------------- 44.8/216.1 MB 18.2 MB/s eta 0:00:10\n",
            "   -------- ------------------------------- 45.5/216.1 MB 18.7 MB/s eta 0:00:10\n",
            "   -------- ------------------------------- 46.2/216.1 MB 18.2 MB/s eta 0:00:10\n",
            "   -------- ------------------------------- 46.9/216.1 MB 18.2 MB/s eta 0:00:10\n",
            "   -------- ------------------------------- 47.9/216.1 MB 18.2 MB/s eta 0:00:10\n",
            "   --------- ------------------------------ 48.9/216.1 MB 18.7 MB/s eta 0:00:09\n",
            "   --------- ------------------------------ 49.8/216.1 MB 18.7 MB/s eta 0:00:09\n",
            "   --------- ------------------------------ 50.6/216.1 MB 18.7 MB/s eta 0:00:09\n",
            "   --------- ------------------------------ 51.5/216.1 MB 18.7 MB/s eta 0:00:09\n",
            "   --------- ------------------------------ 52.6/216.1 MB 18.7 MB/s eta 0:00:09\n",
            "   --------- ------------------------------ 53.4/216.1 MB 18.2 MB/s eta 0:00:09\n",
            "   ---------- ----------------------------- 54.2/216.1 MB 18.7 MB/s eta 0:00:09\n",
            "   ---------- ----------------------------- 55.2/216.1 MB 18.7 MB/s eta 0:00:09\n",
            "   ---------- ----------------------------- 56.0/216.1 MB 18.7 MB/s eta 0:00:09\n",
            "   ---------- ----------------------------- 56.9/216.1 MB 18.7 MB/s eta 0:00:09\n",
            "   ---------- ----------------------------- 57.7/216.1 MB 18.2 MB/s eta 0:00:09\n",
            "   ---------- ----------------------------- 58.6/216.1 MB 18.7 MB/s eta 0:00:09\n",
            "   ----------- ---------------------------- 59.5/216.1 MB 18.2 MB/s eta 0:00:09\n",
            "   ----------- ---------------------------- 60.2/216.1 MB 18.2 MB/s eta 0:00:09\n",
            "   ----------- ---------------------------- 61.1/216.1 MB 18.2 MB/s eta 0:00:09\n",
            "   ----------- ---------------------------- 61.9/216.1 MB 17.7 MB/s eta 0:00:09\n",
            "   ----------- ---------------------------- 62.9/216.1 MB 18.2 MB/s eta 0:00:09\n",
            "   ----------- ---------------------------- 63.7/216.1 MB 18.2 MB/s eta 0:00:09\n",
            "   ----------- ---------------------------- 64.5/216.1 MB 18.2 MB/s eta 0:00:09\n",
            "   ------------ --------------------------- 65.2/216.1 MB 17.2 MB/s eta 0:00:09\n",
            "   ------------ --------------------------- 66.1/216.1 MB 17.3 MB/s eta 0:00:09\n",
            "   ------------ --------------------------- 67.0/216.1 MB 17.3 MB/s eta 0:00:09\n",
            "   ------------ --------------------------- 68.0/216.1 MB 17.7 MB/s eta 0:00:09\n",
            "   ------------ --------------------------- 68.9/216.1 MB 17.2 MB/s eta 0:00:09\n",
            "   ------------ --------------------------- 69.7/216.1 MB 17.7 MB/s eta 0:00:09\n",
            "   ------------- -------------------------- 70.6/216.1 MB 18.2 MB/s eta 0:00:09\n",
            "   ------------- -------------------------- 71.4/216.1 MB 18.2 MB/s eta 0:00:08\n",
            "   ------------- -------------------------- 72.3/216.1 MB 17.7 MB/s eta 0:00:09\n",
            "   ------------- -------------------------- 73.0/216.1 MB 17.7 MB/s eta 0:00:09\n",
            "   ------------- -------------------------- 73.9/216.1 MB 18.2 MB/s eta 0:00:08\n",
            "   ------------- -------------------------- 74.9/216.1 MB 19.2 MB/s eta 0:00:08\n",
            "   -------------- ------------------------- 75.8/216.1 MB 18.7 MB/s eta 0:00:08\n",
            "   -------------- ------------------------- 76.6/216.1 MB 18.7 MB/s eta 0:00:08\n",
            "   -------------- ------------------------- 77.5/216.1 MB 18.7 MB/s eta 0:00:08\n",
            "   -------------- ------------------------- 78.1/216.1 MB 18.7 MB/s eta 0:00:08\n",
            "   -------------- ------------------------- 78.8/216.1 MB 17.7 MB/s eta 0:00:08\n",
            "   -------------- ------------------------- 79.7/216.1 MB 18.7 MB/s eta 0:00:08\n",
            "   -------------- ------------------------- 80.6/216.1 MB 17.7 MB/s eta 0:00:08\n",
            "   --------------- ------------------------ 81.3/216.1 MB 18.2 MB/s eta 0:00:08\n",
            "   --------------- ------------------------ 82.1/216.1 MB 18.2 MB/s eta 0:00:08\n",
            "   --------------- ------------------------ 83.0/216.1 MB 18.2 MB/s eta 0:00:08\n",
            "   --------------- ------------------------ 83.8/216.1 MB 17.7 MB/s eta 0:00:08\n",
            "   --------------- ------------------------ 84.7/216.1 MB 17.7 MB/s eta 0:00:08\n",
            "   --------------- ------------------------ 85.4/216.1 MB 17.7 MB/s eta 0:00:08\n",
            "   --------------- ------------------------ 86.3/216.1 MB 17.7 MB/s eta 0:00:08\n",
            "   ---------------- ----------------------- 87.1/216.1 MB 18.2 MB/s eta 0:00:08\n",
            "   ---------------- ----------------------- 88.0/216.1 MB 17.7 MB/s eta 0:00:08\n",
            "   ---------------- ----------------------- 88.8/216.1 MB 18.2 MB/s eta 0:00:08\n",
            "   ---------------- ----------------------- 89.5/216.1 MB 18.2 MB/s eta 0:00:07\n",
            "   ---------------- ----------------------- 90.1/216.1 MB 18.2 MB/s eta 0:00:07\n",
            "   ---------------- ----------------------- 90.8/216.1 MB 18.7 MB/s eta 0:00:07\n",
            "   ---------------- ----------------------- 91.7/216.1 MB 18.2 MB/s eta 0:00:07\n",
            "   ----------------- ---------------------- 92.6/216.1 MB 18.2 MB/s eta 0:00:07\n",
            "   ----------------- ---------------------- 93.6/216.1 MB 18.7 MB/s eta 0:00:07\n",
            "   ----------------- ---------------------- 94.6/216.1 MB 18.7 MB/s eta 0:00:07\n",
            "   ----------------- ---------------------- 95.2/216.1 MB 18.7 MB/s eta 0:00:07\n",
            "   ----------------- ---------------------- 96.1/216.1 MB 18.7 MB/s eta 0:00:07\n",
            "   ----------------- ---------------------- 97.0/216.1 MB 18.7 MB/s eta 0:00:07\n",
            "   ------------------ --------------------- 97.9/216.1 MB 18.7 MB/s eta 0:00:07\n",
            "   ------------------ --------------------- 98.8/216.1 MB 18.7 MB/s eta 0:00:07\n",
            "   ------------------ --------------------- 99.7/216.1 MB 18.7 MB/s eta 0:00:07\n",
            "   ------------------ -------------------- 100.4/216.1 MB 19.3 MB/s eta 0:00:07\n",
            "   ------------------ -------------------- 101.2/216.1 MB 18.7 MB/s eta 0:00:07\n",
            "   ------------------ -------------------- 102.1/216.1 MB 18.7 MB/s eta 0:00:07\n",
            "   ------------------ -------------------- 102.9/216.1 MB 19.3 MB/s eta 0:00:06\n",
            "   ------------------ -------------------- 103.7/216.1 MB 18.7 MB/s eta 0:00:07\n",
            "   ------------------ -------------------- 104.5/216.1 MB 18.7 MB/s eta 0:00:06\n",
            "   ------------------- ------------------- 105.3/216.1 MB 18.7 MB/s eta 0:00:06\n",
            "   ------------------- ------------------- 106.1/216.1 MB 19.2 MB/s eta 0:00:06\n",
            "   ------------------- ------------------- 106.8/216.1 MB 18.7 MB/s eta 0:00:06\n",
            "   ------------------- ------------------- 107.6/216.1 MB 19.3 MB/s eta 0:00:06\n",
            "   ------------------- ------------------- 108.3/216.1 MB 18.7 MB/s eta 0:00:06\n",
            "   ------------------- ------------------- 109.2/216.1 MB 18.7 MB/s eta 0:00:06\n",
            "   ------------------- ------------------- 109.9/216.1 MB 19.3 MB/s eta 0:00:06\n",
            "   ------------------- ------------------- 110.7/216.1 MB 19.2 MB/s eta 0:00:06\n",
            "   -------------------- ------------------ 111.5/216.1 MB 19.3 MB/s eta 0:00:06\n",
            "   -------------------- ------------------ 112.3/216.1 MB 19.3 MB/s eta 0:00:06\n",
            "   -------------------- ------------------ 113.1/216.1 MB 18.7 MB/s eta 0:00:06\n",
            "   -------------------- ------------------ 114.1/216.1 MB 19.2 MB/s eta 0:00:06\n",
            "   -------------------- ------------------ 115.0/216.1 MB 18.7 MB/s eta 0:00:06\n",
            "   -------------------- ------------------ 115.9/216.1 MB 18.7 MB/s eta 0:00:06\n",
            "   --------------------- ----------------- 116.8/216.1 MB 18.7 MB/s eta 0:00:06\n",
            "   --------------------- ----------------- 117.7/216.1 MB 18.7 MB/s eta 0:00:06\n",
            "   --------------------- ----------------- 118.7/216.1 MB 18.7 MB/s eta 0:00:06\n",
            "   --------------------- ----------------- 119.7/216.1 MB 18.7 MB/s eta 0:00:06\n",
            "   --------------------- ----------------- 120.6/216.1 MB 19.3 MB/s eta 0:00:05\n",
            "   --------------------- ----------------- 121.4/216.1 MB 18.7 MB/s eta 0:00:06\n",
            "   ---------------------- ---------------- 122.2/216.1 MB 19.3 MB/s eta 0:00:05\n",
            "   ---------------------- ---------------- 123.1/216.1 MB 18.7 MB/s eta 0:00:05\n",
            "   ---------------------- ---------------- 124.1/216.1 MB 19.3 MB/s eta 0:00:05\n",
            "   ---------------------- ---------------- 124.9/216.1 MB 19.2 MB/s eta 0:00:05\n",
            "   ---------------------- ---------------- 126.0/216.1 MB 18.7 MB/s eta 0:00:05\n",
            "   ---------------------- ---------------- 126.9/216.1 MB 19.3 MB/s eta 0:00:05\n",
            "   ----------------------- --------------- 127.9/216.1 MB 18.7 MB/s eta 0:00:05\n",
            "   ----------------------- --------------- 128.8/216.1 MB 19.3 MB/s eta 0:00:05\n",
            "   ----------------------- --------------- 129.8/216.1 MB 19.2 MB/s eta 0:00:05\n",
            "   ----------------------- --------------- 130.8/216.1 MB 18.7 MB/s eta 0:00:05\n",
            "   ----------------------- --------------- 131.7/216.1 MB 18.7 MB/s eta 0:00:05\n",
            "   ----------------------- --------------- 132.7/216.1 MB 19.3 MB/s eta 0:00:05\n",
            "   ------------------------ -------------- 133.7/216.1 MB 19.3 MB/s eta 0:00:05\n",
            "   ------------------------ -------------- 134.6/216.1 MB 19.8 MB/s eta 0:00:05\n",
            "   ------------------------ -------------- 135.5/216.1 MB 19.2 MB/s eta 0:00:05\n",
            "   ------------------------ -------------- 136.3/216.1 MB 19.3 MB/s eta 0:00:05\n",
            "   ------------------------ -------------- 137.1/216.1 MB 19.8 MB/s eta 0:00:04\n",
            "   ------------------------ -------------- 137.9/216.1 MB 19.2 MB/s eta 0:00:05\n",
            "   ------------------------- ------------- 138.8/216.1 MB 19.3 MB/s eta 0:00:05\n",
            "   ------------------------- ------------- 139.5/216.1 MB 19.3 MB/s eta 0:00:04\n",
            "   ------------------------- ------------- 140.4/216.1 MB 19.3 MB/s eta 0:00:04\n",
            "   ------------------------- ------------- 141.3/216.1 MB 19.9 MB/s eta 0:00:04\n",
            "   ------------------------- ------------- 142.2/216.1 MB 19.3 MB/s eta 0:00:04\n",
            "   ------------------------- ------------- 143.0/216.1 MB 18.7 MB/s eta 0:00:04\n",
            "   ------------------------- ------------- 143.8/216.1 MB 18.7 MB/s eta 0:00:04\n",
            "   -------------------------- ------------ 144.7/216.1 MB 19.3 MB/s eta 0:00:04\n",
            "   -------------------------- ------------ 145.3/216.1 MB 18.7 MB/s eta 0:00:04\n",
            "   -------------------------- ------------ 146.3/216.1 MB 18.7 MB/s eta 0:00:04\n",
            "   -------------------------- ------------ 147.2/216.1 MB 18.7 MB/s eta 0:00:04\n",
            "   -------------------------- ------------ 148.2/216.1 MB 19.3 MB/s eta 0:00:04\n",
            "   -------------------------- ------------ 149.1/216.1 MB 19.3 MB/s eta 0:00:04\n",
            "   --------------------------- ----------- 149.9/216.1 MB 18.7 MB/s eta 0:00:04\n",
            "   --------------------------- ----------- 150.7/216.1 MB 18.7 MB/s eta 0:00:04\n",
            "   --------------------------- ----------- 151.8/216.1 MB 19.3 MB/s eta 0:00:04\n",
            "   --------------------------- ----------- 152.7/216.1 MB 19.3 MB/s eta 0:00:04\n",
            "   --------------------------- ----------- 153.6/216.1 MB 19.2 MB/s eta 0:00:04\n",
            "   --------------------------- ----------- 154.3/216.1 MB 19.3 MB/s eta 0:00:04\n",
            "   ---------------------------- ---------- 155.2/216.1 MB 19.3 MB/s eta 0:00:04\n",
            "   ---------------------------- ---------- 155.8/216.1 MB 18.7 MB/s eta 0:00:04\n",
            "   ---------------------------- ---------- 156.5/216.1 MB 18.7 MB/s eta 0:00:04\n",
            "   ---------------------------- ---------- 157.2/216.1 MB 18.2 MB/s eta 0:00:04\n",
            "   ---------------------------- ---------- 158.0/216.1 MB 18.2 MB/s eta 0:00:04\n",
            "   ---------------------------- ---------- 158.9/216.1 MB 18.7 MB/s eta 0:00:04\n",
            "   ---------------------------- ---------- 159.2/216.1 MB 18.2 MB/s eta 0:00:04\n",
            "   ---------------------------- ---------- 159.2/216.1 MB 18.2 MB/s eta 0:00:04\n",
            "   ---------------------------- ---------- 160.0/216.1 MB 16.4 MB/s eta 0:00:04\n",
            "   ----------------------------- --------- 160.8/216.1 MB 16.4 MB/s eta 0:00:04\n",
            "   ----------------------------- --------- 161.8/216.1 MB 16.0 MB/s eta 0:00:04\n",
            "   ----------------------------- --------- 162.7/216.1 MB 16.8 MB/s eta 0:00:04\n",
            "   ----------------------------- --------- 163.7/216.1 MB 16.4 MB/s eta 0:00:04\n",
            "   ----------------------------- --------- 164.4/216.1 MB 16.4 MB/s eta 0:00:04\n",
            "   ----------------------------- --------- 165.3/216.1 MB 16.4 MB/s eta 0:00:04\n",
            "   ------------------------------ -------- 166.3/216.1 MB 16.4 MB/s eta 0:00:04\n",
            "   ------------------------------ -------- 167.2/216.1 MB 16.4 MB/s eta 0:00:03\n",
            "   ------------------------------ -------- 168.1/216.1 MB 17.3 MB/s eta 0:00:03\n",
            "   ------------------------------ -------- 168.8/216.1 MB 16.8 MB/s eta 0:00:03\n",
            "   ------------------------------ -------- 169.7/216.1 MB 19.3 MB/s eta 0:00:03\n",
            "   ------------------------------ -------- 170.4/216.1 MB 18.7 MB/s eta 0:00:03\n",
            "   ------------------------------ -------- 171.3/216.1 MB 19.3 MB/s eta 0:00:03\n",
            "   ------------------------------- ------- 172.3/216.1 MB 18.7 MB/s eta 0:00:03\n",
            "   ------------------------------- ------- 173.3/216.1 MB 19.2 MB/s eta 0:00:03\n",
            "   ------------------------------- ------- 174.2/216.1 MB 19.2 MB/s eta 0:00:03\n",
            "   ------------------------------- ------- 175.2/216.1 MB 19.3 MB/s eta 0:00:03\n",
            "   ------------------------------- ------- 176.1/216.1 MB 19.3 MB/s eta 0:00:03\n",
            "   ------------------------------- ------- 177.1/216.1 MB 18.7 MB/s eta 0:00:03\n",
            "   -------------------------------- ------ 178.0/216.1 MB 18.7 MB/s eta 0:00:03\n",
            "   -------------------------------- ------ 178.7/216.1 MB 18.7 MB/s eta 0:00:03\n",
            "   -------------------------------- ------ 179.6/216.1 MB 19.3 MB/s eta 0:00:02\n",
            "   -------------------------------- ------ 180.6/216.1 MB 19.2 MB/s eta 0:00:02\n",
            "   -------------------------------- ------ 181.4/216.1 MB 19.2 MB/s eta 0:00:02\n",
            "   -------------------------------- ------ 182.2/216.1 MB 19.3 MB/s eta 0:00:02\n",
            "   -------------------------------- ------ 182.3/216.1 MB 17.7 MB/s eta 0:00:02\n",
            "   --------------------------------- ----- 183.2/216.1 MB 17.7 MB/s eta 0:00:02\n",
            "   --------------------------------- ----- 183.9/216.1 MB 17.7 MB/s eta 0:00:02\n",
            "   --------------------------------- ----- 184.8/216.1 MB 17.7 MB/s eta 0:00:02\n",
            "   --------------------------------- ----- 185.7/216.1 MB 17.2 MB/s eta 0:00:02\n",
            "   --------------------------------- ----- 186.4/216.1 MB 17.7 MB/s eta 0:00:02\n",
            "   --------------------------------- ----- 187.2/216.1 MB 17.7 MB/s eta 0:00:02\n",
            "   --------------------------------- ----- 188.3/216.1 MB 17.7 MB/s eta 0:00:02\n",
            "   ---------------------------------- ---- 189.2/216.1 MB 17.7 MB/s eta 0:00:02\n",
            "   ---------------------------------- ---- 190.1/216.1 MB 17.2 MB/s eta 0:00:02\n",
            "   ---------------------------------- ---- 191.0/216.1 MB 17.7 MB/s eta 0:00:02\n",
            "   ---------------------------------- ---- 191.7/216.1 MB 17.3 MB/s eta 0:00:02\n",
            "   ---------------------------------- ---- 192.6/216.1 MB 19.3 MB/s eta 0:00:02\n",
            "   ---------------------------------- ---- 193.5/216.1 MB 19.3 MB/s eta 0:00:02\n",
            "   ----------------------------------- --- 194.2/216.1 MB 18.7 MB/s eta 0:00:02\n",
            "   ----------------------------------- --- 195.1/216.1 MB 18.7 MB/s eta 0:00:02\n",
            "   ----------------------------------- --- 195.9/216.1 MB 18.7 MB/s eta 0:00:02\n",
            "   ----------------------------------- --- 196.9/216.1 MB 19.3 MB/s eta 0:00:01\n",
            "   ----------------------------------- --- 197.6/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   ----------------------------------- --- 197.6/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   ----------------------------------- --- 198.1/216.1 MB 16.4 MB/s eta 0:00:02\n",
            "   ----------------------------------- --- 198.7/216.1 MB 16.0 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 199.6/216.1 MB 16.4 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 200.3/216.1 MB 16.4 MB/s eta 0:00:01\n",
            "   ------------------------------------ -- 201.0/216.1 MB 15.6 MB/s eta 0:00:01\n",
            "   ------------------------------------ -- 201.7/216.1 MB 15.6 MB/s eta 0:00:01\n",
            "   ------------------------------------ -- 202.4/216.1 MB 15.2 MB/s eta 0:00:01\n",
            "   ------------------------------------ -- 203.2/216.1 MB 15.6 MB/s eta 0:00:01\n",
            "   ------------------------------------ -- 203.6/216.1 MB 15.2 MB/s eta 0:00:01\n",
            "   ------------------------------------ -- 204.5/216.1 MB 15.2 MB/s eta 0:00:01\n",
            "   ------------------------------------- - 205.4/216.1 MB 15.2 MB/s eta 0:00:01\n",
            "   ------------------------------------- - 206.4/216.1 MB 15.2 MB/s eta 0:00:01\n",
            "   ------------------------------------- - 207.3/216.1 MB 15.6 MB/s eta 0:00:01\n",
            "   ------------------------------------- - 208.3/216.1 MB 17.2 MB/s eta 0:00:01\n",
            "   ------------------------------------- - 209.2/216.1 MB 17.2 MB/s eta 0:00:01\n",
            "   ------------------------------------- - 210.1/216.1 MB 17.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  211.0/216.1 MB 17.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  212.0/216.1 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  212.9/216.1 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  213.9/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  214.8/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  215.8/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  216.1/216.1 MB 18.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 216.1/216.1 MB 4.9 MB/s eta 0:00:00\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
            "   ---- ----------------------------------- 0.7/6.3 MB 21.5 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 1.6/6.3 MB 17.6 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 2.7/6.3 MB 19.3 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 3.6/6.3 MB 19.3 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 4.3/6.3 MB 19.5 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 5.2/6.3 MB 19.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.2/6.3 MB 19.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 6.3/6.3 MB 16.8 MB/s eta 0:00:00\n",
            "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
            "   ---------------------------------------- 0.0/199.1 kB ? eta -:--:--\n",
            "   --------------------------------------- 199.1/199.1 kB 11.8 MB/s eta 0:00:00\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "   ---------------------------------------- 0.0/134.9 kB ? eta -:--:--\n",
            "   ---------------------------------------- 134.9/134.9 kB 7.8 MB/s eta 0:00:00\n",
            "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
            "   --------------- ------------------------ 0.8/2.0 MB 17.0 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 1.7/2.0 MB 21.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.0/2.0 MB 18.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.0/2.0 MB 14.5 MB/s eta 0:00:00\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
            "   --------------------------------------  532.5/536.2 kB 11.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 536.2/536.2 kB 8.3 MB/s eta 0:00:00\n",
            "Installing collected packages: mpmath, sympy, networkx, jinja2, fsspec, filelock, torch\n",
            "Successfully installed filelock-3.18.0 fsspec-2025.5.1 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 sympy-1.14.0 torch-2.7.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\Thanush\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "#Installing torch\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0450f82b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchvision\n",
            "  Downloading torchvision-0.22.1-cp311-cp311-win_amd64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\thanush\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (2.1.3)\n",
            "Requirement already satisfied: torch==2.7.1 in c:\\users\\thanush\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (2.7.1)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Downloading pillow-11.2.1-cp311-cp311-win_amd64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\thanush\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.7.1->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\thanush\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.7.1->torchvision) (4.14.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\thanush\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.7.1->torchvision) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\thanush\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.7.1->torchvision) (3.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\thanush\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.7.1->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\thanush\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.7.1->torchvision) (2025.5.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\thanush\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.13.3->torch==2.7.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\thanush\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch==2.7.1->torchvision) (3.0.2)\n",
            "Downloading torchvision-0.22.1-cp311-cp311-win_amd64.whl (1.7 MB)\n",
            "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.0/1.7 MB 660.6 kB/s eta 0:00:03\n",
            "   -- ------------------------------------- 0.1/1.7 MB 1.1 MB/s eta 0:00:02\n",
            "   ---- ----------------------------------- 0.2/1.7 MB 1.3 MB/s eta 0:00:02\n",
            "   ------ --------------------------------- 0.3/1.7 MB 1.7 MB/s eta 0:00:01\n",
            "   ----------- ---------------------------- 0.5/1.7 MB 2.6 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 0.9/1.7 MB 3.8 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 1.3/1.7 MB 4.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  1.7/1.7 MB 5.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.7/1.7 MB 5.4 MB/s eta 0:00:00\n",
            "Downloading pillow-11.2.1-cp311-cp311-win_amd64.whl (2.7 MB)\n",
            "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
            "   ------------ --------------------------- 0.8/2.7 MB 17.0 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 1.6/2.7 MB 17.2 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 2.4/2.7 MB 17.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.7/2.7 MB 14.2 MB/s eta 0:00:00\n",
            "Installing collected packages: pillow, torchvision\n",
            "Successfully installed pillow-11.2.1 torchvision-0.22.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\Thanush\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "#Installing torchvision\n",
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "623dfb49",
      "metadata": {
        "id": "623dfb49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch Training time: 41.93 seconds\n",
            "Test accuracy: 0.9680\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])\n",
        "train_loader = DataLoader(datasets.MNIST(root='./data', train=True, transform=transform, download=True), batch_size=32)\n",
        "test_loader = DataLoader(datasets.MNIST(root='./data', train=False, transform=transform, download=True), batch_size=1000)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 64)    \n",
        "        self.fc2 = nn.Linear(64, 10)    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))    \n",
        "        return self.fc2(x)    \n",
        "\n",
        "model = Net()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "start = time.time()\n",
        "for epoch in range(5):\n",
        "    for x, y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "end = time.time()\n",
        "print(f\"PyTorch Training time: {end - start:.2f} seconds\")\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        output = model(x)\n",
        "        pred = output.argmax(1)\n",
        "        correct += (pred == y).sum().item()\n",
        "print(f\"Test accuracy: {correct / len(test_loader.dataset):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6dbdab0",
      "metadata": {
        "id": "f6dbdab0"
      },
      "source": [
        "## Convert PyTorch model to ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WuMKMhHc8aLF",
      "metadata": {
        "id": "WuMKMhHc8aLF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.18.0-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in c:\\users\\thanush\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from onnx) (2.1.3)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in c:\\users\\thanush\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in c:\\users\\thanush\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from onnx) (4.14.0)\n",
            "Downloading onnx-1.18.0-cp311-cp311-win_amd64.whl (15.8 MB)\n",
            "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/15.8 MB 640.0 kB/s eta 0:00:25\n",
            "   ---------------------------------------- 0.1/15.8 MB 825.8 kB/s eta 0:00:20\n",
            "   ---------------------------------------- 0.1/15.8 MB 1.0 MB/s eta 0:00:16\n",
            "    --------------------------------------- 0.2/15.8 MB 1.4 MB/s eta 0:00:11\n",
            "   - -------------------------------------- 0.5/15.8 MB 2.4 MB/s eta 0:00:07\n",
            "   - -------------------------------------- 0.6/15.8 MB 2.5 MB/s eta 0:00:06\n",
            "   -- ------------------------------------- 1.1/15.8 MB 3.6 MB/s eta 0:00:05\n",
            "   --- ------------------------------------ 1.6/15.8 MB 4.6 MB/s eta 0:00:04\n",
            "   ----- ---------------------------------- 2.2/15.8 MB 5.8 MB/s eta 0:00:03\n",
            "   ------- -------------------------------- 3.0/15.8 MB 7.1 MB/s eta 0:00:02\n",
            "   --------- ------------------------------ 3.7/15.8 MB 8.1 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 4.5/15.8 MB 9.0 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 5.3/15.8 MB 9.7 MB/s eta 0:00:02\n",
            "   --------------- ------------------------ 6.1/15.8 MB 10.1 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 6.9/15.8 MB 10.7 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 7.5/15.8 MB 10.9 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 8.3/15.8 MB 11.2 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 8.9/15.8 MB 11.4 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 9.8/15.8 MB 11.8 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 10.7/15.8 MB 15.6 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 11.4/15.8 MB 16.8 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 12.3/15.8 MB 17.2 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 12.8/15.8 MB 17.7 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 13.8/15.8 MB 17.2 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 14.7/15.8 MB 17.7 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 15.5/15.8 MB 17.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  15.8/15.8 MB 18.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  15.8/15.8 MB 18.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 15.8/15.8 MB 15.2 MB/s eta 0:00:00\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.18.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\Thanush\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Installing ONNX\n",
        "!pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "09925e9a",
      "metadata": {
        "id": "09925e9a"
      },
      "outputs": [],
      "source": [
        "dummy_input = torch.randn(1, 784)\n",
        "torch.onnx.export(model, dummy_input, \"model.onnx\",\n",
        "                  input_names=[\"input\"], output_names=[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sv4P-dSS_GQB",
      "metadata": {
        "id": "sv4P-dSS_GQB"
      },
      "source": [
        "## TensorFlow custom training loop using tf.GradientTape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KH-sDlHq_Gdw",
      "metadata": {
        "id": "KH-sDlHq_Gdw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/5\n",
            "Step 0, Loss: 2.2949, Accuracy: 0.0938\n",
            "Step 100, Loss: 0.8792, Accuracy: 0.7317\n",
            "Step 200, Loss: 0.2799, Accuracy: 0.8012\n",
            "Step 300, Loss: 0.1383, Accuracy: 0.8355\n",
            "Step 400, Loss: 0.2365, Accuracy: 0.8536\n",
            "Step 500, Loss: 0.0939, Accuracy: 0.8667\n",
            "Step 600, Loss: 0.2381, Accuracy: 0.8762\n",
            "Step 700, Loss: 0.1575, Accuracy: 0.8823\n",
            "Step 800, Loss: 0.3133, Accuracy: 0.8872\n",
            "Step 900, Loss: 0.1738, Accuracy: 0.8924\n",
            "Step 1000, Loss: 0.1689, Accuracy: 0.8965\n",
            "Step 1100, Loss: 0.2571, Accuracy: 0.9005\n",
            "Step 1200, Loss: 0.1427, Accuracy: 0.9033\n",
            "Step 1300, Loss: 0.1695, Accuracy: 0.9056\n",
            "Step 1400, Loss: 0.4465, Accuracy: 0.9080\n",
            "Step 1500, Loss: 0.3101, Accuracy: 0.9109\n",
            "Step 1600, Loss: 0.0241, Accuracy: 0.9129\n",
            "Step 1700, Loss: 0.1204, Accuracy: 0.9154\n",
            "Step 1800, Loss: 0.0548, Accuracy: 0.9177\n",
            "Training Accuracy for epoch 1: 0.9190\n",
            "\n",
            "Epoch 2/5\n",
            "Step 0, Loss: 0.0807, Accuracy: 0.9688\n",
            "Step 100, Loss: 0.0358, Accuracy: 0.9570\n",
            "Step 200, Loss: 0.1340, Accuracy: 0.9577\n",
            "Step 300, Loss: 0.2204, Accuracy: 0.9575\n",
            "Step 400, Loss: 0.0560, Accuracy: 0.9584\n",
            "Step 500, Loss: 0.1370, Accuracy: 0.9581\n",
            "Step 600, Loss: 0.0384, Accuracy: 0.9580\n",
            "Step 700, Loss: 0.1770, Accuracy: 0.9578\n",
            "Step 800, Loss: 0.0850, Accuracy: 0.9573\n",
            "Step 900, Loss: 0.4214, Accuracy: 0.9579\n",
            "Step 1000, Loss: 0.5014, Accuracy: 0.9575\n",
            "Step 1100, Loss: 0.0566, Accuracy: 0.9576\n",
            "Step 1200, Loss: 0.1643, Accuracy: 0.9574\n",
            "Step 1300, Loss: 0.2198, Accuracy: 0.9578\n",
            "Step 1400, Loss: 0.0353, Accuracy: 0.9582\n",
            "Step 1500, Loss: 0.0736, Accuracy: 0.9580\n",
            "Step 1600, Loss: 0.1095, Accuracy: 0.9587\n",
            "Step 1700, Loss: 0.0869, Accuracy: 0.9592\n",
            "Step 1800, Loss: 0.1371, Accuracy: 0.9596\n",
            "Training Accuracy for epoch 2: 0.9601\n",
            "\n",
            "Epoch 3/5\n",
            "Step 0, Loss: 0.1435, Accuracy: 0.9375\n",
            "Step 100, Loss: 0.0460, Accuracy: 0.9684\n",
            "Step 200, Loss: 0.1162, Accuracy: 0.9692\n",
            "Step 300, Loss: 0.0197, Accuracy: 0.9697\n",
            "Step 400, Loss: 0.0987, Accuracy: 0.9701\n",
            "Step 500, Loss: 0.0916, Accuracy: 0.9699\n",
            "Step 600, Loss: 0.1407, Accuracy: 0.9698\n",
            "Step 700, Loss: 0.1319, Accuracy: 0.9696\n",
            "Step 800, Loss: 0.3755, Accuracy: 0.9701\n",
            "Step 900, Loss: 0.1565, Accuracy: 0.9701\n",
            "Step 1000, Loss: 0.0122, Accuracy: 0.9701\n",
            "Step 1100, Loss: 0.0149, Accuracy: 0.9700\n",
            "Step 1200, Loss: 0.0122, Accuracy: 0.9701\n",
            "Step 1300, Loss: 0.0665, Accuracy: 0.9698\n",
            "Step 1400, Loss: 0.0152, Accuracy: 0.9698\n",
            "Step 1500, Loss: 0.0129, Accuracy: 0.9699\n",
            "Step 1600, Loss: 0.1053, Accuracy: 0.9701\n",
            "Step 1700, Loss: 0.0306, Accuracy: 0.9704\n",
            "Step 1800, Loss: 0.0118, Accuracy: 0.9705\n",
            "Training Accuracy for epoch 3: 0.9707\n",
            "\n",
            "Epoch 4/5\n",
            "Step 0, Loss: 0.0899, Accuracy: 1.0000\n",
            "Step 100, Loss: 0.1498, Accuracy: 0.9756\n",
            "Step 200, Loss: 0.1498, Accuracy: 0.9754\n",
            "Step 300, Loss: 0.0083, Accuracy: 0.9766\n",
            "Step 400, Loss: 0.1404, Accuracy: 0.9768\n",
            "Step 500, Loss: 0.1765, Accuracy: 0.9767\n",
            "Step 600, Loss: 0.0821, Accuracy: 0.9765\n",
            "Step 700, Loss: 0.0322, Accuracy: 0.9761\n",
            "Step 800, Loss: 0.0419, Accuracy: 0.9764\n",
            "Step 900, Loss: 0.0300, Accuracy: 0.9766\n",
            "Step 1000, Loss: 0.0097, Accuracy: 0.9766\n",
            "Step 1100, Loss: 0.0263, Accuracy: 0.9762\n",
            "Step 1200, Loss: 0.0812, Accuracy: 0.9759\n",
            "Step 1300, Loss: 0.0341, Accuracy: 0.9752\n",
            "Step 1400, Loss: 0.0216, Accuracy: 0.9752\n",
            "Step 1500, Loss: 0.0236, Accuracy: 0.9755\n",
            "Step 1600, Loss: 0.0110, Accuracy: 0.9756\n",
            "Step 1700, Loss: 0.0336, Accuracy: 0.9759\n",
            "Step 1800, Loss: 0.0610, Accuracy: 0.9763\n",
            "Training Accuracy for epoch 4: 0.9762\n",
            "\n",
            "Epoch 5/5\n",
            "Step 0, Loss: 0.2805, Accuracy: 0.9688\n",
            "Step 100, Loss: 0.0428, Accuracy: 0.9799\n",
            "Step 200, Loss: 0.0530, Accuracy: 0.9809\n",
            "Step 300, Loss: 0.0580, Accuracy: 0.9824\n",
            "Step 400, Loss: 0.0625, Accuracy: 0.9822\n",
            "Step 500, Loss: 0.0595, Accuracy: 0.9822\n",
            "Step 600, Loss: 0.0219, Accuracy: 0.9818\n",
            "Step 700, Loss: 0.0618, Accuracy: 0.9811\n",
            "Step 800, Loss: 0.0300, Accuracy: 0.9810\n",
            "Step 900, Loss: 0.0463, Accuracy: 0.9808\n",
            "Step 1000, Loss: 0.0554, Accuracy: 0.9806\n",
            "Step 1100, Loss: 0.0082, Accuracy: 0.9806\n",
            "Step 1200, Loss: 0.0144, Accuracy: 0.9805\n",
            "Step 1300, Loss: 0.1047, Accuracy: 0.9803\n",
            "Step 1400, Loss: 0.1838, Accuracy: 0.9800\n",
            "Step 1500, Loss: 0.0218, Accuracy: 0.9799\n",
            "Step 1600, Loss: 0.0107, Accuracy: 0.9801\n",
            "Step 1700, Loss: 0.0347, Accuracy: 0.9802\n",
            "Step 1800, Loss: 0.1736, Accuracy: 0.9804\n",
            "Training Accuracy for epoch 5: 0.9803\n",
            "\n",
            "TF Training time: 216.05 seconds\n",
            "Test Accuracy: 0.9741\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "# Loading and preprocessing the data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0   # Fill in normalization factor\n",
        "x_test = x_test / 255.0   # Fill in normalization factor\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Preparing datasets\n",
        "batch_size = 32         # Fill same batch size as in first TF example\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
        "\n",
        "# Defining the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(28, 28)),    # Fill size\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),    # Fill number of neurons and activation\n",
        "    tf.keras.layers.Dense(10, activation='softmax')     # Fill number of neurons and activation\n",
        "])\n",
        "\n",
        "# Defining loss, optimizer, and metrics\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "test_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "# Training loop\n",
        "epochs = 5\n",
        "start = time.time()\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    for step, (x_batch, y_batch) in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(x_batch, training=True)\n",
        "            loss = loss_fn(y_batch, logits)\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "        train_acc_metric.update_state(y_batch, logits)\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Step {step}, Loss: {loss.numpy():.4f}, Accuracy: {train_acc_metric.result().numpy():.4f}\")\n",
        "\n",
        "    print(f\"Training Accuracy for epoch {epoch+1}: {train_acc_metric.result().numpy():.4f}\")\n",
        "    train_acc_metric.reset_state()\n",
        "end = time.time()\n",
        "print(f\"\\nTF Training time: {end - start:.2f} seconds\")\n",
        "\n",
        "# Evaluation loop\n",
        "for x_batch, y_batch in test_dataset:\n",
        "    test_logits = model(x_batch, training=False)\n",
        "    test_acc_metric.update_state(y_batch, test_logits)\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc_metric.result().numpy():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E4Nlg4lb_qdW",
      "metadata": {
        "id": "E4Nlg4lb_qdW"
      },
      "source": [
        "## Performance Optimization with Graph Execution using @tf.function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jmu_hciK_qle",
      "metadata": {
        "id": "Jmu_hciK_qle"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/5\n",
            "Step 0, Loss: 2.4329, Accuracy: 0.1250\n",
            "Step 100, Loss: 0.5306, Accuracy: 0.7296\n",
            "Step 200, Loss: 0.3480, Accuracy: 0.8005\n",
            "Step 300, Loss: 0.2732, Accuracy: 0.8326\n",
            "Step 400, Loss: 0.1765, Accuracy: 0.8520\n",
            "Step 500, Loss: 0.2427, Accuracy: 0.8645\n",
            "Step 600, Loss: 0.4893, Accuracy: 0.8738\n",
            "Step 700, Loss: 0.3610, Accuracy: 0.8799\n",
            "Step 800, Loss: 0.1545, Accuracy: 0.8854\n",
            "Step 900, Loss: 0.2645, Accuracy: 0.8896\n",
            "Step 1000, Loss: 0.1534, Accuracy: 0.8941\n",
            "Step 1100, Loss: 0.1284, Accuracy: 0.8975\n",
            "Step 1200, Loss: 0.2175, Accuracy: 0.9007\n",
            "Step 1300, Loss: 0.1207, Accuracy: 0.9026\n",
            "Step 1400, Loss: 0.2155, Accuracy: 0.9048\n",
            "Step 1500, Loss: 0.2218, Accuracy: 0.9074\n",
            "Step 1600, Loss: 0.1198, Accuracy: 0.9098\n",
            "Step 1700, Loss: 0.0646, Accuracy: 0.9119\n",
            "Step 1800, Loss: 0.2575, Accuracy: 0.9144\n",
            "Training Accuracy for epoch 1: 0.9159\n",
            "\n",
            "Epoch 2/5\n",
            "Step 0, Loss: 0.3035, Accuracy: 0.9375\n",
            "Step 100, Loss: 0.1154, Accuracy: 0.9533\n",
            "Step 200, Loss: 0.2005, Accuracy: 0.9521\n",
            "Step 300, Loss: 0.1845, Accuracy: 0.9516\n",
            "Step 400, Loss: 0.0402, Accuracy: 0.9524\n",
            "Step 500, Loss: 0.0638, Accuracy: 0.9525\n",
            "Step 600, Loss: 0.2141, Accuracy: 0.9539\n",
            "Step 700, Loss: 0.1078, Accuracy: 0.9536\n",
            "Step 800, Loss: 0.2247, Accuracy: 0.9535\n",
            "Step 900, Loss: 0.1272, Accuracy: 0.9543\n",
            "Step 1000, Loss: 0.1581, Accuracy: 0.9554\n",
            "Step 1100, Loss: 0.2626, Accuracy: 0.9559\n",
            "Step 1200, Loss: 0.0530, Accuracy: 0.9561\n",
            "Step 1300, Loss: 0.3696, Accuracy: 0.9562\n",
            "Step 1400, Loss: 0.0456, Accuracy: 0.9561\n",
            "Step 1500, Loss: 0.0723, Accuracy: 0.9563\n",
            "Step 1600, Loss: 0.0438, Accuracy: 0.9573\n",
            "Step 1700, Loss: 0.0268, Accuracy: 0.9577\n",
            "Step 1800, Loss: 0.1329, Accuracy: 0.9583\n",
            "Training Accuracy for epoch 2: 0.9585\n",
            "\n",
            "Epoch 3/5\n",
            "Step 0, Loss: 0.0871, Accuracy: 0.9688\n",
            "Step 100, Loss: 0.1291, Accuracy: 0.9660\n",
            "Step 200, Loss: 0.0585, Accuracy: 0.9656\n",
            "Step 300, Loss: 0.0891, Accuracy: 0.9670\n",
            "Step 400, Loss: 0.0240, Accuracy: 0.9663\n",
            "Step 500, Loss: 0.0954, Accuracy: 0.9678\n",
            "Step 600, Loss: 0.1078, Accuracy: 0.9678\n",
            "Step 700, Loss: 0.1360, Accuracy: 0.9675\n",
            "Step 800, Loss: 0.0253, Accuracy: 0.9669\n",
            "Step 900, Loss: 0.0684, Accuracy: 0.9672\n",
            "Step 1000, Loss: 0.0161, Accuracy: 0.9678\n",
            "Step 1100, Loss: 0.1573, Accuracy: 0.9678\n",
            "Step 1200, Loss: 0.0909, Accuracy: 0.9673\n",
            "Step 1300, Loss: 0.0771, Accuracy: 0.9675\n",
            "Step 1400, Loss: 0.0231, Accuracy: 0.9672\n",
            "Step 1500, Loss: 0.0273, Accuracy: 0.9674\n",
            "Step 1600, Loss: 0.0310, Accuracy: 0.9677\n",
            "Step 1700, Loss: 0.0999, Accuracy: 0.9678\n",
            "Step 1800, Loss: 0.1128, Accuracy: 0.9682\n",
            "Training Accuracy for epoch 3: 0.9685\n",
            "\n",
            "Epoch 4/5\n",
            "Step 0, Loss: 0.1075, Accuracy: 0.9688\n",
            "Step 100, Loss: 0.0665, Accuracy: 0.9737\n",
            "Step 200, Loss: 0.2667, Accuracy: 0.9743\n",
            "Step 300, Loss: 0.0212, Accuracy: 0.9738\n",
            "Step 400, Loss: 0.0336, Accuracy: 0.9740\n",
            "Step 500, Loss: 0.0216, Accuracy: 0.9743\n",
            "Step 600, Loss: 0.0154, Accuracy: 0.9744\n",
            "Step 700, Loss: 0.0100, Accuracy: 0.9749\n",
            "Step 800, Loss: 0.1138, Accuracy: 0.9746\n",
            "Step 900, Loss: 0.2935, Accuracy: 0.9746\n",
            "Step 1000, Loss: 0.0831, Accuracy: 0.9746\n",
            "Step 1100, Loss: 0.0344, Accuracy: 0.9744\n",
            "Step 1200, Loss: 0.0149, Accuracy: 0.9746\n",
            "Step 1300, Loss: 0.0886, Accuracy: 0.9744\n",
            "Step 1400, Loss: 0.0604, Accuracy: 0.9746\n",
            "Step 1500, Loss: 0.1745, Accuracy: 0.9748\n",
            "Step 1600, Loss: 0.0102, Accuracy: 0.9749\n",
            "Step 1700, Loss: 0.0314, Accuracy: 0.9751\n",
            "Step 1800, Loss: 0.0111, Accuracy: 0.9752\n",
            "Training Accuracy for epoch 4: 0.9753\n",
            "\n",
            "Epoch 5/5\n",
            "Step 0, Loss: 0.0107, Accuracy: 1.0000\n",
            "Step 100, Loss: 0.0423, Accuracy: 0.9780\n",
            "Step 200, Loss: 0.0802, Accuracy: 0.9792\n",
            "Step 300, Loss: 0.0274, Accuracy: 0.9790\n",
            "Step 400, Loss: 0.0122, Accuracy: 0.9798\n",
            "Step 500, Loss: 0.0678, Accuracy: 0.9802\n",
            "Step 600, Loss: 0.0451, Accuracy: 0.9802\n",
            "Step 700, Loss: 0.0110, Accuracy: 0.9797\n",
            "Step 800, Loss: 0.1911, Accuracy: 0.9796\n",
            "Step 900, Loss: 0.0329, Accuracy: 0.9798\n",
            "Step 1000, Loss: 0.1049, Accuracy: 0.9798\n",
            "Step 1100, Loss: 0.0663, Accuracy: 0.9797\n",
            "Step 1200, Loss: 0.0592, Accuracy: 0.9794\n",
            "Step 1300, Loss: 0.1028, Accuracy: 0.9794\n",
            "Step 1400, Loss: 0.0865, Accuracy: 0.9792\n",
            "Step 1500, Loss: 0.0057, Accuracy: 0.9791\n",
            "Step 1600, Loss: 0.0088, Accuracy: 0.9793\n",
            "Step 1700, Loss: 0.1014, Accuracy: 0.9794\n",
            "Step 1800, Loss: 0.0394, Accuracy: 0.9794\n",
            "Training Accuracy for epoch 5: 0.9795\n",
            "\n",
            "TF Training time: 20.76 seconds\n",
            "Test Accuracy: 0.9729\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "# Loading and preprocessing data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0   # Normalization factor\n",
        "x_test = x_test / 255.0   # Normalization factor\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Preparing datasets\n",
        "batch_size = 32\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
        "\n",
        "# Defining the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(28, 28)),    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),    # Number of neurons and activation\n",
        "    tf.keras.layers.Dense(10, activation='softmax')     #Number of neurons and activation\n",
        "])\n",
        "\n",
        "# Defining loss, optimizer, and metrics\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "test_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "@tf.function  \n",
        "def train_step(x_batch, y_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(x_batch, training=True)\n",
        "        loss = loss_fn(y_batch, logits)\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    train_acc_metric.update_state(y_batch, logits)\n",
        "    return loss\n",
        "\n",
        "# Training loop\n",
        "epochs = 5\n",
        "start = time.time()\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    for step, (x_batch, y_batch) in enumerate(train_dataset):\n",
        "        loss = train_step(x_batch, y_batch)\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Step {step}, Loss: {loss.numpy():.4f}, Accuracy: {train_acc_metric.result().numpy():.4f}\")\n",
        "\n",
        "    print(f\"Training Accuracy for epoch {epoch+1}: {train_acc_metric.result().numpy():.4f}\")\n",
        "    train_acc_metric.reset_state()\n",
        "end = time.time()\n",
        "print(f\"\\nTF Training time: {end - start:.2f} seconds\")\n",
        "\n",
        "# Evaluation loop\n",
        "for x_batch, y_batch in test_dataset:\n",
        "    test_logits = model(x_batch, training=False)\n",
        "    test_acc_metric.update_state(y_batch, test_logits)\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc_metric.result().numpy():.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
